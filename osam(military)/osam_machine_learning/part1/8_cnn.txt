CNN(Convolutional Neural Network)

이전까지 공부했던 내용은 dense layer 혹은 fully connected layer 
XW + b = y
  ___784___           ___128___                 
 |         |         |         |       ___128___         ___128___ 
N|    x    | *    784|    W    | +    |____b____|    = N|____b____|
 |_________|         |_________|            
 
                        weights = 784*128 + 128 = 100480
 input matrix가 들어왔을때 모든 input이 뉴련에 연결되어서 학습된다
 
 문제는 이미지
 fully connected 연산을 하기 위해서 2차원 이미지를 1차원으로 쭉 펴서 input에 넣었다 
 fully는 전체 데이터를 한번에 넣기 때문에 전체 이미지가 한번에 고려된다
 하지만 이미지를 볼때는 쭉 다 연결해서 보는 것이 아닌 특정 지역지역을 보면서 이미지를 확인을 한다. 
 그래서 나온게 CNN
 
 cnn에서 부분적으로 보게 하는 것이 filter
 filter는 matrix형태로 input matrix를 쭉 훓으면서 곱과 합으로 새로운 matrix를 만들어낸다
 CNN에서는 이 filter 안의 내용을 학습시키는 것임
 
 filter의 갯수는 hyperparameter 
 convolution layer는 여러번 거치면서 사용된다. 
 
 Keras를 이용한 cnn실습
 
 -텐서플로 임포트하기
import tensorflow as tf

from tensorflow.keras import datasets, layers, models

 -MNIST 데이터셋 다운로드하고 준비하기
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

train_images = train_images.reshape((60000, 28, 28, 1))
test_images = test_images.reshape((10000, 28, 28, 1))

# 픽셀 값을 0~1 사이로 정규화합니다.
train_images, test_images = train_images / 255.0, test_images / 255.0

 -합성곱 층 만들기
 아래 6줄의 코드에서 Conv2D와 MaxPooling2D 층을 쌓는 일반적인 패턴으로 합성곱 층을 정의한다.
 CNN은 배치(batch) 크기를 제외하고 (이미지 높이, 이미지 너비, 컬러 채널) 크기의 텐서(tensor)를 입력으로 받는다. MNIST 데이터는 (흑백 이미지이기 때문에) 컬러 채널(channel)이 하나지만 컬러 이미지는 (R,G,B) 세 개의 채널을 가집니다. 이 예에서는 MNIST 이미지 포맷인 (28, 28, 1) 크기의 입력을 처리하는 CNN을 정의한다. 이 값을 첫 번째 층의 input_shape 매개변수로 전달한다.
 
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

-마지막에 Dense층 추가하기
모델을 완성하려면 마지막 합성곱 층의 출력 텐서(크기 (4, 4, 64))를 하나 이상의 Dense 층에 주입하여 분류를 수행한다. Dense 층은 벡터(1D)를 입력으로 받는데 현재 출력은 3D 텐서입니다. 먼저 3D 출력을 1D로 펼친다.그다음 하나 이상의 Dense 층을 그 위에 추가한다. MNIST 데이터는 10개의 클래스가 있으므로 마지막에 Dense 층에 10개의 출력과 소프트맥스 활성화 함수를 사용다.


-모델 컴파일과 훈련
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=5)

-모델 평가
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2


-CNN에서 pooling
    convolution을 거쳐 나온 activation maps가 있을때, convolutional layer를 resizing하여 새로운 alyer를 얻는 것 
    data크기를 줄이는 것 
    pooling을 하는 가장큰 이유는 overfitting을 방지하는 것 
    
-cnn에서 padding
    이미지 데이터에서 가장자리들을 특정값으로 둘러주는 과정
    zero padding : 0으로 둘러주는 것
    하는 이유 : 1. 이미지 데이터의 축소를 막기위해
                -convolutional operation에서 input (n*n)이 (f*f) filter를 통해 (n-f+1)*(n-f+1) 이미지로 축소됨
                위와 같이 여러번의 계산을 하는데 초반부터 이미지가 너무 작아져버리면 깊에 학습시킬 데이터가 부족해진다. 
              2. edge pixel data를 충분히 활용하기 위해서 
                -convoultional operation과정에서 가장자리의 데이터들은 안쪽의 데이터에 비해 적게 사용된다. 만약 중요한 정보가 모서리쪽에 있다면 모델의 성능이 떨어질 거이다. 
                이를 방지하기 위해서 모서리부분 데이터를 안쪽으로 넣어주는 과정(padding)을 거치면 가장자리 데이터는 많이 사용될 것이다 .
                
    