{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final evaluation(House Price Predict).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZOVjoSfvxnYnE9zu5bCXH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parksj0923/KORartilleryman/blob/master/Artillery/osam(military)/osam_machine_learning/house_price_predict/Final_evaluation(House_Price_Predict).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK6KEyLIrcvn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "df_missing = df_train.isnull().sum()\n",
        "df_missing = df_missing.sort_values(ascending=False)\n",
        "\n",
        "df_missing = df_missing[df_missing >0]\n",
        "# missing data가 있는 feature를 제거\n",
        "df_train = df_train.drop(df_missing.index.tolist(),axis=1)\n",
        "\n",
        "numeric = [df_train.dtypes[f] for f in df_train.columns]\n",
        "numeric = [f for f in df_train.columns if df_train.dtypes[f] !='object']\n",
        "numeric.remove('Id')\n",
        "numeric.remove('SalePrice')\n",
        "\n",
        "categorical = [f for f in df_train.columns if df_train.dtypes[f] =='object']\n",
        "\n",
        "df_order = pd.DataFrame()\n",
        "feature_name = \"ExterQual\"\n",
        "df_order['val'] = df_train[feature_name].unique()\n",
        "df_order.index = df_order.val\n",
        "\n",
        "df_order['mean_price'] = df_train[[feature_name, 'SalePrice']].groupby(feature_name).mean()['SalePrice']\n",
        "df_order = df_order.sort_values('mean_price')\n",
        "df_order['rank'] = range(1,len(df_order)+1)\n",
        "df_order = df_order['rank'].to_dict()\n",
        "#원본 데이터는 나두는게 좋으니 새로운 feature를 만들어서 추가\n",
        "#apply는 원하는 데이터의 한 row식 접근하면서 새로운 colum에 추가할 수 있음\n",
        "df_train[feature_name + '_rank'] = df_train.apply(lambda x: df_order[x[feature_name]],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-zBrJj7sREn"
      },
      "source": [
        "def add_rank_feature (feature_name, rank_feature_name):\n",
        "  df_order = pd.DataFrame()\n",
        "  df_order['val'] = df_train[feature_name].unique()\n",
        "  df_order.index = df_order.val\n",
        "\n",
        "  df_order['mean_price'] = df_train[[feature_name, 'SalePrice']].groupby(feature_name).mean()['SalePrice']\n",
        "  df_order['rank'] = range(1,len(df_order)+1)\n",
        "  df_order = df_order['rank'].to_dict()\n",
        "\n",
        "  df_train[feature_name + '_rank'] = df_train.apply(lambda x: df_order[x[feature_name]],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFEgse9FsX2l",
        "outputId": "63d1d386-204b-4ab6-a1ec-63753e4a056b"
      },
      "source": [
        "rank_features = []\n",
        "for feature_name in categorical:\n",
        "  \n",
        "  rank_feature_name = feature_name + '_rank'\n",
        "  print(feature_name, '-->', rank_feature_name)\n",
        "  add_rank_feature(feature_name, rank_feature_name)\n",
        "\n",
        "  rank_features.append(rank_feature_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSZoning --> MSZoning_rank\n",
            "Street --> Street_rank\n",
            "LotShape --> LotShape_rank\n",
            "LandContour --> LandContour_rank\n",
            "Utilities --> Utilities_rank\n",
            "LotConfig --> LotConfig_rank\n",
            "LandSlope --> LandSlope_rank\n",
            "Neighborhood --> Neighborhood_rank\n",
            "Condition1 --> Condition1_rank\n",
            "Condition2 --> Condition2_rank\n",
            "BldgType --> BldgType_rank\n",
            "HouseStyle --> HouseStyle_rank\n",
            "RoofStyle --> RoofStyle_rank\n",
            "RoofMatl --> RoofMatl_rank\n",
            "Exterior1st --> Exterior1st_rank\n",
            "Exterior2nd --> Exterior2nd_rank\n",
            "ExterQual --> ExterQual_rank\n",
            "ExterCond --> ExterCond_rank\n",
            "Foundation --> Foundation_rank\n",
            "Heating --> Heating_rank\n",
            "HeatingQC --> HeatingQC_rank\n",
            "CentralAir --> CentralAir_rank\n",
            "KitchenQual --> KitchenQual_rank\n",
            "Functional --> Functional_rank\n",
            "PavedDrive --> PavedDrive_rank\n",
            "SaleType --> SaleType_rank\n",
            "SaleCondition --> SaleCondition_rank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqyoG9jBsYVl",
        "outputId": "45427d0c-a0a0-4c66-bf8d-9843459f48cc"
      },
      "source": [
        "df_processed = df_train[rank_features + numeric]\n",
        "df_processed['SalePrice'] = df_train['SalePrice']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-iw2CEjszrr"
      },
      "source": [
        "corrmat = df_processed.corr()\n",
        "df_features = corrmat.sort_values(by=['SalePrice'])['SalePrice']\n",
        "NUM_FEATURES = 30\n",
        "x = df_processed[df_features[-NUM_FEATURES-1:-1].index.tolist()]\n",
        "y = df_processed['SalePrice']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.1, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9XhFtf2tT-p"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#k개 각각의 데이터를 전처리하기 귀찮으니 전처리를 먼저 하고 간다\n",
        "# min_max scaler는 각각의 칼럼의 범위가 제각각이니까 0-1사이로 맞춰주고 한다\n",
        "#data preprocessing\n",
        "x_min_max_scaler = MinMaxScaler()\n",
        "x_min_max_scaler.fit(x)\n",
        "scaled_x = x_min_max_scaler.transform(x)\n",
        "\n",
        "y_min_max_scaler = MinMaxScaler()\n",
        "y_min_max_scaler.fit(np.array(y).reshape(-1,1))\n",
        "scaled_y = y_min_max_scaler.transform(np.array(y).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByRVpdN-sfZ2"
      },
      "source": [
        "# save numpy data\n",
        "with open('x.npy','wb') as f:\n",
        "  np.save(f,x)\n",
        "\n",
        "with open('y.npy','wb') as f:\n",
        "  np.save(f,y)\n",
        "\n",
        "with open('scaled_x.npy','wb') as f:\n",
        "  np.save(f,scaled_x)\n",
        "\n",
        "with open('scaled_y.npy','wb') as f:\n",
        "  np.save(f,scaled_y)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgCskqOHsf9G"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# K-fold cross validation\n",
        "K = 10\n",
        "kf = KFold(n_splits=K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKpiF_HkuGq2"
      },
      "source": [
        "##Linear regression (Lasso) \n",
        "y = Xw 선형모델\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtSYFxtSuA6_",
        "outputId": "31960e24-be22-499e-dc08-866b24f54b55"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn import metrics\n",
        "rmses = []\n",
        "for train_index, test_index in kf.split(scaled_x):\n",
        "  #print(\"Test:\", test_index, \"trains:\", train_index)\n",
        "\n",
        "  scaled_x_train, scaled_x_test = scaled_x[train_index], scaled_x[test_index]\n",
        "  scaled_y_train, scaled_y_test = scaled_y[train_index], scaled_y[test_index]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "  #print(x_train,shape, x_test.shape)\n",
        "  #print(y_train.shape, y_test.shape)\n",
        "\n",
        "  #training\n",
        "  model = Lasso()\n",
        "  model = model.fit(scaled_x_train, scaled_y_train)\n",
        "\n",
        "  #evaluation\n",
        "  pred = model.predict(scaled_x_test).reshape((-1,1))  #0-1\n",
        "  pred = y_min_max_scaler.inverse_transform(pred)  #원상복구된 스케일\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test,pred))\n",
        "\n",
        "  print(rmse)\n",
        "  print(\"===============================\")\n",
        "  rmses.append(rmse)\n",
        "print(\"average rmse:\", np.mean(rmses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68479.61848137801\n",
            "===============================\n",
            "80011.92820033105\n",
            "===============================\n",
            "79275.65958882873\n",
            "===============================\n",
            "82868.15912800275\n",
            "===============================\n",
            "96386.20490927555\n",
            "===============================\n",
            "76808.56629102639\n",
            "===============================\n",
            "72198.44861652121\n",
            "===============================\n",
            "71213.04254017191\n",
            "===============================\n",
            "90347.61467595294\n",
            "===============================\n",
            "72613.27897372228\n",
            "===============================\n",
            "average rmse: 79020.25214052107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgb158fH_caW"
      },
      "source": [
        "##MLP(Multi-layer Perceptron)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-tAz1Ge-cGS",
        "outputId": "118f3a24-daf8-4912-9fad-039834d40a78"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "rmses = []\n",
        "for train_index, test_index in kf.split(scaled_x):\n",
        "\n",
        "  scaled_x_train, scaled_x_test = scaled_x[train_index], scaled_x[test_index]\n",
        "  scaled_y_train, scaled_y_test = scaled_y[train_index], scaled_y[test_index]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "\n",
        "  #training\n",
        "  model = keras.Sequential(\n",
        "     [\n",
        "      keras.Input(shape=scaled_x_train.shape[-1]),\n",
        "      layers.Dense(96, activation='relu'),\n",
        "      layers.Dense(48, activation='relu'),\n",
        "      layers.Dense(1)\n",
        "     ]\n",
        "  )\n",
        "\n",
        "  model.compile(loss = 'mse', optimizer = 'adam')\n",
        "  early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n",
        "  model.fit(scaled_x_train, scaled_y_train, batch_size=4, epochs=150,\n",
        "            callbacks=[early_stopping_callback], validation_split=0.05)\n",
        "\n",
        "  #evaluation\n",
        "  pred = model.predict(scaled_x_test).reshape((-1,1))  #0-1\n",
        "  pred = y_min_max_scaler.inverse_transform(pred)  #원상복구된 스케일\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test,pred))\n",
        "\n",
        "  print(rmse)\n",
        "  print(\"===============================\")\n",
        "  rmses.append(rmse)\n",
        "print(\"average rmse:\", np.mean(rmses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 0.0055 - val_loss: 0.0040\n",
            "Epoch 2/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0020\n",
            "Epoch 3/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 4/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0020\n",
            "Epoch 5/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0037\n",
            "Epoch 6/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 7/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "Epoch 8/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 9/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0032\n",
            "385437388.9109486\n",
            "===============================\n",
            "Epoch 1/150\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 0.0069 - val_loss: 0.0017\n",
            "Epoch 2/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0018\n",
            "Epoch 3/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0027\n",
            "Epoch 4/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 5/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 6/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0021\n",
            "Epoch 7/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0014\n",
            "Epoch 8/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 9/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 10/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 11/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 12/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 13/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 14/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 15/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0014\n",
            "Epoch 16/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 9.7119e-04 - val_loss: 0.0016\n",
            "Epoch 17/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.7236e-04 - val_loss: 0.0012\n",
            "Epoch 18/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 19/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 20/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 9.7952e-04 - val_loss: 0.0014\n",
            "Epoch 21/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 7.3699e-04 - val_loss: 0.0017\n",
            "331370702.71760356\n",
            "===============================\n",
            "Epoch 1/150\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 0.0067 - val_loss: 0.0030\n",
            "Epoch 2/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0023\n",
            "Epoch 3/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0021\n",
            "Epoch 4/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 5/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0015\n",
            "Epoch 6/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0026\n",
            "Epoch 7/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 8/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 9/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0037\n",
            "Epoch 10/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0036\n",
            "Epoch 11/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 12/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0018\n",
            "Epoch 13/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0025\n",
            "Epoch 14/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 15/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 16/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0010\n",
            "Epoch 17/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 18/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 19/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0014\n",
            "Epoch 20/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 9.7450e-04 - val_loss: 0.0010\n",
            "Epoch 21/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.5423e-04 - val_loss: 0.0012\n",
            "Epoch 22/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.0978e-04 - val_loss: 0.0013\n",
            "Epoch 23/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.4687e-04 - val_loss: 0.0013\n",
            "Epoch 24/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 9.9286e-04\n",
            "Epoch 25/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0012\n",
            "Epoch 26/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.7652e-04 - val_loss: 0.0013\n",
            "Epoch 27/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 9.4201e-04 - val_loss: 9.6410e-04\n",
            "Epoch 28/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 7.5370e-04 - val_loss: 0.0013\n",
            "Epoch 29/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 7.8589e-04 - val_loss: 0.0012\n",
            "Epoch 30/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 7.8707e-04 - val_loss: 9.8426e-04\n",
            "Epoch 31/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.5673e-04 - val_loss: 0.0010\n",
            "Epoch 32/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0012\n",
            "Epoch 33/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.5617e-04 - val_loss: 0.0013\n",
            "Epoch 34/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.6767e-04 - val_loss: 0.0019\n",
            "1636695806.492933\n",
            "===============================\n",
            "Epoch 1/150\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 0.0061 - val_loss: 0.0020\n",
            "Epoch 2/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0019\n",
            "Epoch 3/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0019\n",
            "Epoch 4/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0016\n",
            "Epoch 5/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0043\n",
            "Epoch 6/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 7/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 8/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 9/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 10/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 11/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0012\n",
            "Epoch 12/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 13/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 14/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0015\n",
            "Epoch 15/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0015\n",
            "Epoch 16/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 17/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 18/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.8944e-04 - val_loss: 0.0012\n",
            "Epoch 19/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 20/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.2468e-04 - val_loss: 0.0014\n",
            "1448280006.7911615\n",
            "===============================\n",
            "Epoch 1/150\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 0.0049 - val_loss: 0.0015\n",
            "Epoch 2/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0013\n",
            "Epoch 3/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
            "Epoch 4/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 5/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0020\n",
            "Epoch 6/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 7/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "Epoch 8/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 9/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "824804479.3740728\n",
            "===============================\n",
            "Epoch 1/150\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 0.0063 - val_loss: 0.0024\n",
            "Epoch 2/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0025\n",
            "Epoch 3/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0049\n",
            "Epoch 4/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 5/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0031\n",
            "Epoch 6/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0034\n",
            "Epoch 7/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0025\n",
            "Epoch 8/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0022\n",
            "Epoch 9/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 10/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0024\n",
            "Epoch 11/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 12/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 13/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 14/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 15/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 16/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 17/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0015\n",
            "Epoch 18/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 9.9210e-04 - val_loss: 0.0026\n",
            "Epoch 19/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0012\n",
            "Epoch 20/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0030\n",
            "Epoch 21/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 22/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 23/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.8480e-04 - val_loss: 0.0017\n",
            "Epoch 24/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 25/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.3165e-04 - val_loss: 0.0011\n",
            "Epoch 26/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.7649e-04 - val_loss: 0.0015\n",
            "Epoch 27/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 28/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 9.2328e-04 - val_loss: 0.0019\n",
            "Epoch 29/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.2597e-04 - val_loss: 0.0013\n",
            "Epoch 30/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 6.6965e-04 - val_loss: 0.0013\n",
            "Epoch 31/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 6.5923e-04 - val_loss: 0.0015\n",
            "Epoch 32/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 8.2908e-04 - val_loss: 0.0017\n",
            "1699971617.5127816\n",
            "===============================\n",
            "Epoch 1/150\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 0.0059 - val_loss: 0.0017\n",
            "Epoch 2/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0015\n",
            "Epoch 3/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0014\n",
            "Epoch 4/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0033\n",
            "Epoch 5/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0012\n",
            "Epoch 6/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 7/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0035\n",
            "Epoch 8/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0011\n",
            "Epoch 9/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0017\n",
            "Epoch 10/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 11/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 12/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 13/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 14/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 15/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "1221556599.0904472\n",
            "===============================\n",
            "Epoch 1/150\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 0.0055 - val_loss: 0.0039\n",
            "Epoch 2/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0015\n",
            "Epoch 3/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0022\n",
            "Epoch 4/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 5/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0013\n",
            "Epoch 6/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 7/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0014\n",
            "Epoch 8/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
            "Epoch 9/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 10/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0020\n",
            "Epoch 11/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 12/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "1182329837.4340725\n",
            "===============================\n",
            "Epoch 1/150\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 0.0056 - val_loss: 0.0019\n",
            "Epoch 2/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0020\n",
            "Epoch 3/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 4/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0018\n",
            "Epoch 5/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0026\n",
            "Epoch 6/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 7/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 8/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 9/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 10/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "1295538767.450734\n",
            "===============================\n",
            "Epoch 1/150\n",
            "312/312 [==============================] - 1s 2ms/step - loss: 0.0069 - val_loss: 0.0087\n",
            "Epoch 2/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0110\n",
            "Epoch 3/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0130\n",
            "Epoch 4/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0151\n",
            "Epoch 5/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0133\n",
            "Epoch 6/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0146\n",
            "Epoch 7/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0160\n",
            "Epoch 8/150\n",
            "312/312 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0174\n",
            "1461250732.4186003\n",
            "===============================\n",
            "average rmse: 1148723593.8193355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t0JMqdeAhnp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yi1sp_PAtFq"
      },
      "source": [
        "##Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W-58psNAurq",
        "outputId": "cabe9862-edb0-4128-bf32-2556166902d0"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "rmses = []\n",
        "for train_index, test_index in kf.split(scaled_x):\n",
        "  #print(\"Test:\", test_index, \"trains:\", train_index)\n",
        "\n",
        "  scaled_x_train, scaled_x_test = scaled_x[train_index], scaled_x[test_index]\n",
        "  scaled_y_train, scaled_y_test = scaled_y[train_index], scaled_y[test_index]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "  #print(x_train,shape, x_test.shape)\n",
        "  #print(y_train.shape, y_test.shape)\n",
        "\n",
        "  #training\n",
        "  model = DecisionTreeRegressor(random_state = 0)\n",
        "  model = model.fit(scaled_x_train, scaled_y_train)\n",
        "\n",
        "  #evaluation\n",
        "  pred = model.predict(scaled_x_test).reshape((-1,1))\n",
        "  pred = y_min_max_scaler.inverse_transform(pred)\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test,pred))\n",
        "\n",
        "  print(rmse)\n",
        "  print(\"===============================\")\n",
        "  rmses.append(rmse)\n",
        "print(\"average rmse:\", np.mean(rmses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34070.24666059374\n",
            "===============================\n",
            "36792.7899139313\n",
            "===============================\n",
            "38478.76115412554\n",
            "===============================\n",
            "48437.07536071929\n",
            "===============================\n",
            "43629.418260220555\n",
            "===============================\n",
            "34903.48882540429\n",
            "===============================\n",
            "32715.948804354426\n",
            "===============================\n",
            "38051.52842228641\n",
            "===============================\n",
            "59230.083416528454\n",
            "===============================\n",
            "38853.31003934798\n",
            "===============================\n",
            "average rmse: 40516.2650857512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRaoaOfeBB28"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndQp1-uoBDT8",
        "outputId": "7bf5fdc0-5086-4511-977e-b3bd7b7a53d0"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rmses = []\n",
        "for train_index, test_index in kf.split(scaled_x):\n",
        "  #print(\"Test:\", test_index, \"trains:\", train_index)\n",
        "\n",
        "  scaled_x_train, scaled_x_test = scaled_x[train_index], scaled_x[test_index]\n",
        "  scaled_y_train, scaled_y_test = scaled_y[train_index], scaled_y[test_index]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "  #print(x_train,shape, x_test.shape)\n",
        "  #print(y_train.shape, y_test.shape)\n",
        "\n",
        "  #training\n",
        "  model = RandomForestRegressor(random_state = 0, n_estimators = 200)\n",
        "  model = model.fit(scaled_x_train, scaled_y_train)\n",
        "\n",
        "  #evaluation\n",
        "  pred = model.predict(scaled_x_test).reshape((-1,1))\n",
        "  pred = y_min_max_scaler.inverse_transform(pred)\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test,pred))\n",
        "\n",
        "  print(rmse)\n",
        "  print(\"===============================\")\n",
        "  rmses.append(rmse)\n",
        "print(\"average rmse:\", np.mean(rmses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26474.567325638072\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27462.385207784337\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22252.075782071384\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40756.658420543274\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32914.350613998664\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26753.189306771892\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25278.078951487416\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24177.79106533606\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40942.91436992498\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27919.82190051351\n",
            "===============================\n",
            "average rmse: 29493.183294406957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9SV9G64BQA0"
      },
      "source": [
        "##AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXGov-X5BRJv",
        "outputId": "ca84bc6e-43d3-4f6e-d104-1bf89cd129a1"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "rmses = []\n",
        "for train_index, test_index in kf.split(scaled_x):\n",
        "  #print(\"Test:\", test_index, \"trains:\", train_index)\n",
        "\n",
        "  scaled_x_train, scaled_x_test = scaled_x[train_index], scaled_x[test_index]\n",
        "  scaled_y_train, scaled_y_test = scaled_y[train_index], scaled_y[test_index]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "  #print(x_train,shape, x_test.shape)\n",
        "  #print(y_train.shape, y_test.shape)\n",
        "\n",
        "  #training\n",
        "  model = AdaBoostRegressor(random_state = 0, n_estimators = 200)\n",
        "  model = model.fit(scaled_x_train, scaled_y_train)\n",
        "\n",
        "  #evaluation\n",
        "  pred = model.predict(scaled_x_test).reshape((-1,1))\n",
        "  pred = y_min_max_scaler.inverse_transform(pred)\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test,pred))\n",
        "\n",
        "  print(rmse)\n",
        "  print(\"===============================\")\n",
        "  rmses.append(rmse)\n",
        "print(\"average rmse:\", np.mean(rmses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30670.99212382827\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31297.310045005834\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31372.609145958246\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43601.10924332043\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39926.80145753425\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32133.319650581696\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31819.440177753517\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30623.153644286078\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46314.34158762049\n",
            "===============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34231.72422634499\n",
            "===============================\n",
            "average rmse: 35199.08013022338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXqu68drDkUx"
      },
      "source": [
        "##XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR88XNO8DhPR",
        "outputId": "b3d149a4-5814-4c6f-fb0b-dd590ef2f7ec"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "rmses = []\n",
        "for train_index, test_index in kf.split(scaled_x):\n",
        "  #print(\"Test:\", test_index, \"trains:\", train_index)\n",
        "\n",
        "  scaled_x_train, scaled_x_test = scaled_x[train_index], scaled_x[test_index]\n",
        "  scaled_y_train, scaled_y_test = scaled_y[train_index], scaled_y[test_index]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "  #print(x_train,shape, x_test.shape)\n",
        "  #print(y_train.shape, y_test.shape)\n",
        "\n",
        "  #training\n",
        "  model = XGBRegressor(random_state = 0, n_estimators = 200)\n",
        "  model = model.fit(scaled_x_train, scaled_y_train)\n",
        "\n",
        "  #evaluation\n",
        "  pred = model.predict(scaled_x_test).reshape((-1,1))\n",
        "  pred = y_min_max_scaler.inverse_transform(pred)\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test,pred))\n",
        "\n",
        "  print(rmse)\n",
        "  print(\"===============================\")\n",
        "  rmses.append(rmse)\n",
        "print(\"average rmse:\", np.mean(rmses))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11:14:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "22570.376747612765\n",
            "===============================\n",
            "[11:14:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "24646.83596423113\n",
            "===============================\n",
            "[11:14:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "23302.28305688471\n",
            "===============================\n",
            "[11:14:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "43276.780661287245\n",
            "===============================\n",
            "[11:14:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "30420.16603047583\n",
            "===============================\n",
            "[11:14:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "25190.01461840584\n",
            "===============================\n",
            "[11:14:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "29858.352121148237\n",
            "===============================\n",
            "[11:14:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "22758.499207177134\n",
            "===============================\n",
            "[11:14:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "29910.270557404336\n",
            "===============================\n",
            "[11:14:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "26466.115866992484\n",
            "===============================\n",
            "average rmse: 27839.969483161974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0gtCh7GDsXv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}